{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRO\n",
    "so this notebook is to clean up the data based on the decisions made in ML_eda.ipynb, without all the graphs and text. I will probably convert this into a .py file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the fact table from bq\n",
    "is this going to work outside of bigquery studio? Might need a dockerfile and poetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_gbq\n",
    "from google.cloud import bigquery\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charles.doyne/Code/emea3-capstone-ml/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:2379: UserWarning: A progress bar was requested, but there was an error loading the tqdm library. Please install tqdm to use the progress bar functionality.\n",
      "  record_batch = self.to_arrow(\n"
     ]
    }
   ],
   "source": [
    "client = bigquery.Client(project=\"dt-grad-emea3-cap-dev\")\n",
    "query = \"\"\"SELECT * FROM `dt-grad-emea3-cap-dev.dataform.fct_vehicle_listings`\"\"\"\n",
    "result = client.query(query)\n",
    "\n",
    "df = pandas_gbq.read_gbq(query, project_id='dt-grad-emea3-cap-dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['price', 'model', 'fuel', 'odometer', 'title_status', 'transmission', 'cylinder_count', 'car_year', 'car_condition', 'state']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we need to do error handling.\n",
    "E.g.\n",
    " - Are there negative prices? Shouldn't be, think it's impossible because craigslist wouldn't allow. If there are just remove them and carry on\n",
    " - Are the environment variables valid inputs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things that could be environment variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRICE_LOWER_BOUND = 1000\n",
    "PRICE_UPPER_BOUND = df['price'].quantile(0.999) # this has to be changed to a percentile or a fixed value to be configurable by the client\n",
    "\n",
    "TOP_X_MODELS = 30\n",
    "\n",
    "ODO_LOWER_BOUND = 1000\n",
    "ODO_UPPER_BOUND = 500000\n",
    "\n",
    "CAR_YEAR_THRESHOLD = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keeping rows with prices between our chosen price range\n",
    "bounded_price_df =  df[(df['price'] >= PRICE_LOWER_BOUND) & (df['price'] <= PRICE_UPPER_BOUND)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only including rows that are from the top X (30 atm) models (they will have enough data)\n",
    "# we could change this to set a threshold limit for the min amount of data a model has e.g. 400 datapoints per model to be included\n",
    "top_models = bounded_price_df['model'].value_counts().nlargest(TOP_X_MODELS).index\n",
    "top_models_df = bounded_price_df[bounded_price_df['model'].isin(top_models)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounded_odometer_df = top_models_df[(top_models_df['odometer'] >= ODO_LOWER_BOUND) & (top_models_df['odometer'] <= ODO_UPPER_BOUND)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only including rows that have 4,6,8 cylinders as there is little data for the other options\n",
    "cylinder_filtered_df = bounded_odometer_df[bounded_odometer_df['cylinder_count'].isin([4, 6, 8])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only including cars that are from years since the CAR_YEAR_THRESHOLD\n",
    "filtered_by_year_df = cylinder_filtered_df[cylinder_filtered_df['car_year'] >= CAR_YEAR_THRESHOLD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keeping rows with cars that have good or excellent condition\n",
    "filtered_condition_df = filtered_by_year_df[filtered_by_year_df['car_condition'].isin(['good', 'excellent'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keeping automatic transmission\n",
    "transmission_df = filtered_condition_df[filtered_condition_df['transmission'] == 'automatic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keeping clean cars\n",
    "title_status_df = transmission_df[transmission_df['title_status']== 'clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keeping gas cars\n",
    "fuel_df = title_status_df[title_status_df['fuel'] == 'gas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping leftover unwanted columns\n",
    "car_df = fuel_df.drop(columns=['fuel', 'title_status', 'transmission'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalising and encoding for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df['car_condition'] = car_df['car_condition'].map({'good': 0, 'excellent': 1})\n",
    "scaler = StandardScaler()\n",
    "car_df['odometer'] = scaler.fit_transform(car_df[['odometer']])\n",
    "car_df = pd.get_dummies(car_df, columns=['model'])\n",
    "car_df = pd.get_dummies(car_df, columns=['state'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing it up for bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.columns = car_df.columns.str.replace('-', '_')\n",
    "car_df.columns = car_df.columns.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(car_df, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tbf we might not need to send it back to bigquery. We could just save it locally and train an ML model on it in python using scikit or smth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_gbq(destination_table='Machine_learning.training_car_data', project_id='dt-grad-emea3-cap-dev', if_exists='replace')\n",
    "test_df.to_gbq(destination_table='Machine_learning.test_car_data', project_id='dt-grad-emea3-cap-dev', if_exists='replace')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
